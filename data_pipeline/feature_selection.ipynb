{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs Feature Selection on the cleaned dataset by applying various statistical feature selection techniques. A simple voting mechanism is implemented at the end to shortlist the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold, RFECV, f_regression, mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('data_versions/clean_data.csv')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter Methods\n",
    "# Variance Threshold\n",
    "vt = VarianceThreshold(threshold=0.1)\n",
    "vt.fit(clean_df)\n",
    "vt_features = clean_df.columns[vt.get_support()]\n",
    "print(f\"Filter Method (Variance Threshold) {len(vt_features)} features: \\n\", vt_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised feature selection techniques require input and target variables\n",
    "X = clean_df.drop('risk', axis=1)\n",
    "y = clean_df['risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-test\n",
    "f_scores, p_values = f_regression(X, y)\n",
    "f_pvalues = pd.Series(p_values, index=X.columns)\n",
    "anova_features = f_pvalues[f_pvalues < 0.05].sort_values().index\n",
    "\n",
    "# Due to most of the features getting low p-value, a stricter filter is applied.\n",
    "anova_features = f_pvalues[f_pvalues==0]\n",
    "print(f\"Filter Method (ANOVA F-test) {len(anova_features)}: \\n\", anova_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_features = f_pvalues[f_pvalues==0].index\n",
    "anova_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient of the feature scores are plotted for all feature selection techniques to find the optimal number of features. An example using mutual information selection method is provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.abs(np.gradient(sorted(f_scores)[::-1]))[2:15])\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True, which='both')\n",
    "plt.grid(color='lightgray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Absolute Gradient')\n",
    "plt.title('Absolute Gradient of Sorted Feature Importance Scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual Information\n",
    "mi_scores = mutual_info_regression(X, y)\n",
    "mi_pvalues = pd.Series(mi_scores, index=X.columns)\n",
    "mi_features = mi_pvalues.sort_values(ascending=False).index\n",
    "print(\"Filter Method (Mutual Information):\\n\", mi_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_features = mi_pvalues.sort_values(ascending=False)[:34].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.abs(np.gradient(sorted(mi_scores)[::-1]))[30:35])\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True, which='both')\n",
    "plt.grid(color='lightgray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Absolute Gradient')\n",
    "plt.title('Absolute Gradient of Sorted Feature Importance Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Wrapper Methods\n",
    "# Recursive Feature Elimination (RFE)\n",
    "model = LinearRegression()\n",
    "rfe = RFECV(model)\n",
    "rfe.fit(X, y)\n",
    "wrapper_features = X.columns[rfe.get_support()]\n",
    "print(\"Wrapper Method (RFE):\", wrapper_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Feature selector using Ridge Regression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeCV\n",
    "model = RidgeCV().fit(X,y)\n",
    "sfs_backward = SequentialFeatureSelector(\n",
    "    model, direction=\"backward\"\n",
    ").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_features = X.columns[sfs_backward.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embedded Methods\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "embedded_features = X.columns[rf.feature_importances_.argsort()[::-1]]\n",
    "print(\"Embedded Method (Random Forest):\", embedded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(np.gradient(sorted(rf.feature_importances_)[::-1]))[10:20])\n",
    "np.abs(np.gradient(sorted(rf.feature_importances_)[::-1]))[10:20].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_features = X.columns[rf.feature_importances_.argsort()[::-1][:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the feature lists into a single list\n",
    "from collections import Counter\n",
    "all_features = vt_features.to_list() + anova_features.to_list() + mi_features.to_list() + wrapper_features.to_list() + embedded_features.to_list() + sfs_features.tolist()\n",
    "\n",
    "# Count the occurrences of each feature\n",
    "feature_counts = Counter(all_features)\n",
    "\n",
    "# Sort the features by their vote count\n",
    "sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Print the selected features based on a voting threshold\n",
    "voting_threshold = 5\n",
    "selected_features = [feature for feature, votes in sorted_features if votes >= voting_threshold]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features += ['risk','event_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = clean_df[selected_features]\n",
    "train_df.to_csv('selected_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vyoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
